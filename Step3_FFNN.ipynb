{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4ab8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2167a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit constants \n",
    "NUM_SEQUENCES_PER_BATCH = 128\n",
    "\n",
    "# The file to train the language model on\n",
    "TRAIN_FILE_1 = 'data/jchat_paired.csv' \n",
    "TRAIN_FILE_2 = 'data/chigiri_train_w_tone.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114fdcd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get out all tone from both files\n",
    "labels = set()\n",
    "for file_path in [TRAIN_FILE_1, TRAIN_FILE_2]:\n",
    "    df_data = pd.read_csv(file_path)\n",
    "    labels = labels | set(df_data[\"tone\"])\n",
    "\n",
    "# sort the labels so it will be the same every time\n",
    "labels = sorted(list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a89ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readin_data(file_path, labels):\n",
    "    \"\"\"\n",
    "    Read in the csv, change the tone to integer labels, and format the data to a list of dictionaries\n",
    "    \n",
    "    Args:\n",
    "        file_path: file path\n",
    "        labels: a list of full sorted labels\n",
    "\n",
    "    Return:\n",
    "        formatted_data: a list of dictionaries of prev_line and integer label of tone\n",
    "    \"\"\"\n",
    "    df_data = pd.read_csv(file_path)\n",
    "    df_data[\"label\"] = df_data[\"tone\"].apply(lambda x: labels.index(x))\n",
    "    \n",
    "    \n",
    "    formatted_data = [{\"prev_line\": prev, \"label\": label} \n",
    "                      for prev, label in zip(df_data[\"prev_line\"], df_data[\"label\"])]\n",
    "    \n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "023c6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tohoku tokenizer and bert model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n",
    "bert_model = AutoModel.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n",
    "\n",
    "def get_embeddings_batch(texts: list[str], tokenizer, model, batch_size=16):\n",
    "    \"\"\"\n",
    "    Get the embedding at once.\n",
    "    \n",
    "    Args:\n",
    "        texts: a list of text to be embedded.\n",
    "        tokenizer: tokenizer model\n",
    "        model: bert embedding model\n",
    "        batch_size: batch_size\n",
    "        \n",
    "    Return:\n",
    "        embedded_torch: embedded vector in torch format\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "\n",
    "    # loop through sentences in batch_size and do embedding\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :] \n",
    "            \n",
    "            # append the result\n",
    "            all_embeddings.append(cls_embeddings)\n",
    "\n",
    "    return torch.cat(all_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "575d719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it takes a long time to do embeddding. save the embedding to reduce time \n",
    "DATA1_EMBED_PATH = \"Jchat_X_embeddings.pt\"\n",
    "DATA1_LABEL_PATH = \"Jchat_y_labels.pt\"\n",
    "DATA2_EMBED_PATH = \"Chigiri_X_embeddings.pt\"\n",
    "DATA2_LABEL_PATH = \"Chigiri_y_labels.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b621ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(X: list[str], y: list[int], embed_path, label_path, batch_size: int,\n",
    "                       test_pct: float = 0.2, shuffle: bool = True,\n",
    "                       tokenizer=None, model=None):\n",
    "    \"\"\"\n",
    "    Do embedding and create dataloaders for training.\n",
    "    \n",
    "    Args:\n",
    "        X: text of previous lines\n",
    "        y: tone labels in integer\n",
    "        embed_path: embedding path for pre-done embedding or to save the current embedding\n",
    "        label_path: label path for pre-done labels or to save the current labels\n",
    "        batch_size: batch size for embedding\n",
    "        test_pct: % of test set\n",
    "        shuffle (bool): shuffle while seperating train/test set\n",
    "        tokenizer: pre-trained Tohoku tokenizer\n",
    "        model: pre-trained Tohoku bert model\n",
    "        \n",
    "    Return:\n",
    "        train_loader, test_loader: tensor data loader for FFNN training\n",
    "    \"\"\"\n",
    "    # use the embedded file if existed\n",
    "    if os.path.exists(embed_path) and os.path.exists(label_path):\n",
    "        print(\"Found cached embeddings\")\n",
    "        X_tensor = torch.load(embed_path)\n",
    "        y_tensor = torch.load(label_path)\n",
    "    else:\n",
    "        print(\"No cached embeddings found.\")\n",
    "        y_tensor = torch.tensor(y)\n",
    "        X_tensor = get_embeddings_batch(X, tokenizer, model)\n",
    "        \n",
    "        # save the embedding for future use\n",
    "        torch.save(X_tensor, embed_path)\n",
    "        torch.save(y_tensor, label_path)\n",
    "        print(\"Saved embeddings to disk.\")\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_tensor, y_tensor, test_size=test_pct, stratify=y_tensor\n",
    "    )\n",
    "\n",
    "    # create train and text tensordataset\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "    # create data loader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c38f54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFNN setting mostly from hw4 \n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim=768, hidden_units=128, num_classes=len(labels)):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_units)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(hidden_units, num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.fc1(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.dropout(X)\n",
    "        return self.fc2(X)\n",
    "\n",
    "def train(dataloader, model, epochs=3, lr: float = 1e-4) -> None:\n",
    "    \"\"\"\n",
    "    Train the FFNN.\n",
    "    \n",
    "    Args:\n",
    "        dataloader: dataloader\n",
    "        model: FFNN model to be trained\n",
    "        epochs: # of iteration to train\n",
    "        lr: learning rate\n",
    "    \"\"\"\n",
    "    # initialize Adam optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # change to training mode\n",
    "        model.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        num_batches = len(dataloader)\n",
    "\n",
    "        # loop through each branch\n",
    "        for X, y in tqdm(dataloader, desc=f\"EPOCH {epoch+1}: Training Progress\"):\n",
    "            # Zero the gradients for every batch\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Make predictions for this batch\n",
    "            outputs = model(X)\n",
    "            \n",
    "            # Compute the loss and its gradients\n",
    "            loss = loss_fn(outputs, y)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Average Loss = {(total_loss / num_batches):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96d12b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline(file_path, labels, embed_path, label_path, batch_size: int = NUM_SEQUENCES_PER_BATCH,\n",
    "                  hidden_units=128, epochs=3, lr=0.001,\n",
    "                  test_pct=0.2, trained_model=None):\n",
    "    \"\"\"\n",
    "    Full pipeline to run the training process\n",
    "    \n",
    "    Args:\n",
    "        file_path: file path of the paired csv\n",
    "        labels: collection of tone labels from all datasets\n",
    "        embed_path, label_path: path for pre-done embedding or to save the current embedding\n",
    "        batch_size: batch_size to train the model\n",
    "        hidden_units: hidden units of FFNN\n",
    "        epochs: # of iteration to train\n",
    "        lr: learning rate\n",
    "        test_pct: % of test set\n",
    "        trained_model: previous trained FFNN model\n",
    "        \n",
    "    Returns:\n",
    "        model: trained FFNN model\n",
    "    \"\"\"\n",
    "    # read in data and change format\n",
    "    data = readin_data(file_path, labels)\n",
    "    \n",
    "    # separate X, y\n",
    "    X = [d[\"prev_line\"] for d in data]\n",
    "    y = [d[\"label\"] for d in data]\n",
    "\n",
    "    # dataloader\n",
    "    train_loader, test_loader = create_dataloaders(X, y, embed_path, label_path, \n",
    "                                                   batch_size, test_pct, tokenizer=tokenizer, model=bert_model)\n",
    "    \n",
    "    print(\"Finish processing data\")\n",
    "\n",
    "    if trained_model is None:\n",
    "        # initilize model\n",
    "        model = FFNN(input_dim=768, hidden_units=hidden_units)\n",
    "    else:\n",
    "        model = trained_model\n",
    "\n",
    "    print(\"Finish initializing model, start training\")\n",
    "\n",
    "    # train\n",
    "    train(train_loader, model, epochs, lr)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5771369f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found cached embeddings. Loading from disk...\n",
      "Finish processing data\n",
      "Finish initializing model, start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1: Training Progress: 100%|██████████████| 52/52 [00:00<00:00, 371.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.7554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 2: Training Progress: 100%|██████████████| 52/52 [00:00<00:00, 477.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.5274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 3: Training Progress: 100%|██████████████| 52/52 [00:00<00:00, 534.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 4: Training Progress: 100%|██████████████| 52/52 [00:00<00:00, 513.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.4900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 5: Training Progress: 100%|██████████████| 52/52 [00:00<00:00, 454.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.4732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 6: Training Progress: 100%|██████████████| 52/52 [00:00<00:00, 312.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.4844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train for j-chat dataset\n",
    "half_model = full_pipeline(TRAIN_FILE_1, labels, DATA1_EMBED_PATH, DATA1_LABEL_PATH, epochs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6101f4",
   "metadata": {},
   "source": [
    "# Use Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6279bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found cached embeddings. Loading from disk...\n",
      "Finish processing data\n",
      "Finish initializing model, start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1: Training Progress: 100%|████████████████| 2/2 [00:00<00:00, 274.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.6132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 2: Training Progress: 100%|████████████████| 2/2 [00:00<00:00, 271.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.5785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 3: Training Progress: 100%|████████████████| 2/2 [00:00<00:00, 206.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.6363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 4: Training Progress: 100%|█████████████████| 2/2 [00:00<00:00, 56.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.5428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 5: Training Progress: 100%|████████████████| 2/2 [00:00<00:00, 283.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.4756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 6: Training Progress: 100%|████████████████| 2/2 [00:00<00:00, 286.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.4563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 7: Training Progress: 100%|████████████████| 2/2 [00:00<00:00, 234.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.4761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 8: Training Progress: 100%|████████████████| 2/2 [00:00<00:00, 242.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.5026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 9: Training Progress: 100%|████████████████| 2/2 [00:00<00:00, 323.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.5616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 10: Training Progress: 100%|███████████████| 2/2 [00:00<00:00, 322.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss = 2.5560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train for chigiri-only dataset\n",
    "new_model = full_pipeline(TRAIN_FILE_2, labels, DATA2_EMBED_PATH, DATA2_LABEL_PATH, \n",
    "                          epochs=10, trained_model=half_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99d529e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "MODEL_PATH = \"models/tone_classifier.pt\"\n",
    "torch.save(new_model.state_dict(), MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
